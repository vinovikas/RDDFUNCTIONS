# -*- coding: utf-8 -*-
"""OCC ASSESMENT 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1da-15v1-5E2m0_5thTi8acbaax3b4-56
"""

!pip install -q pyspark

from pyspark.sql import SparkSession
spark = SparkSession.builder.getOrCreate()

print("Spark version:", spark.version)

from google.colab import files
uploaded = files.upload()    # pick your Kaggle CSV file

file_path = list(uploaded.keys())[0]  # first uploaded file
print("Uploaded:", file_path)

df = spark.read.option("header", True).option("inferSchema", True).csv(file_path)
df.printSchema()
df.show(5, truncate=False)

df.createOrReplaceTempView("kaggle_data")

print("✅ SQL View 'kaggle_data' created — you can now query using spark.sql()")

spark.sql("SELECT * FROM kaggle_data LIMIT 10").show()

spark.sql("SELECT COUNT(*) AS total_records FROM kaggle_data").show()

spark.sql("""
SELECT type, COUNT(*) AS count
FROM kaggle_data
GROUP BY type
ORDER BY count DESC
""").show()

spark.sql("""
SELECT country, COUNT(*) AS titles
FROM kaggle_data
WHERE country IS NOT NULL
GROUP BY country
ORDER BY titles DESC
LIMIT 10
""").show()

spark.sql("""
SELECT AVG(duration) AS avg_duration
FROM kaggle_data
WHERE duration IS NOT NULL
""").show()

total = spark.sql("SELECT COUNT(*) AS total FROM kaggle_data").collect()[0]["total"]
by_type = spark.sql("SELECT type, COUNT(*) AS count FROM kaggle_data GROUP BY type")

print(f"Total records = {total}")
by_type.show()

output_df = spark.sql("""
SELECT country, COUNT(*) AS titles
FROM kaggle_data
GROUP BY country
ORDER BY titles DESC
""")
output_df.coalesce(1).write.mode("overwrite").csv("/content/sql_output", header=True)
print("✅ Output saved to /content/sql_output")

print("""
✅ Assessment 2 completed successfully.

We used PySpark SQL to:
• Read a Kaggle dataset into a DataFrame.
• Register it as a SQL view.
• Perform multiple SQL queries (count, group, filter, order).
This demonstrates the use of DataFrame API + SQL engine in Spark.
""")